{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb28745-bb57-4c93-bd32-b1c868a49895",
   "metadata": {},
   "source": [
    "                                                         Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ… \n",
    "                                                         \"ÙˆÙ‚Ù„ Ø±Ø¨ÙŠ Ø²Ø¯Ù†ÙŠ Ø¹Ù„Ù…Ù‹Ø§\"\n",
    "                                                          ØµØ¯Ù‚ Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ø¸ÙŠÙ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154f6e0-9cf7-48d5-8e41-0ae5315db331",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                 Ù„Ø§ ØªÙ†Ø³ÙˆÙ†ÙŠ Ù…Ù† ØµØ§Ù„Ø­ Ø§Ù„Ø¯Ø¹Ø§Ø¡ØŒ ÙˆÙƒØ°Ù„Ùƒ Ø£Ø¨ÙŠ ÙˆØ£Ù…ÙŠ ÙˆØ¥Ø®ÙˆØªÙŠ Ø§Ù„ØµØºØ§Ø±       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8574a56c-91ef-42c7-bfc4-b1c8a5ced371",
   "metadata": {},
   "source": [
    "Course name: Data Manipulation with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a378f-d603-4d1f-9ced-5074655639c4",
   "metadata": {},
   "source": [
    "Course Chapters:\n",
    "1 - Transforming DataFrames\n",
    "2 - Aggregating DataFrames\n",
    "3 - Slicing and Indexing DataFrames\n",
    "4 - Creating and Visualizing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5462d8-5544-417e-aad3-59061973507e",
   "metadata": {},
   "source": [
    "chapter 1 : Transforming DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "178e4938-3d49-44c8-99f7-1aab79e059ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMultible manipulations:\\nBMI_100 = df[df['BMI'] < 100]\\nBMI_height = BMI_100.sort_values('height_cm',ascending=False)\\n\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dogs_data = {\n",
    "    \"name\": [\"Bella\", \"Charlie\", \"Lucy\", \"Cooper\", \"Max\"],\n",
    "    \"breed\": [\"Labrador\", \"Poodle\", \"Chow Chow\", \"Schnauzer\", \"Labrador\"],\n",
    "    \"color\": [\"Brown\", \"Black\", \"Brown\", \"Gray\", \"Black\"],\n",
    "    \"height_cm\": [56, 43, 44, 50, 59],\n",
    "    \"weight_kg\": [34, 54, 30, 17, 29],\n",
    "    \"date_of_birth\": [\"2013-07-01\", \"2016-09-16\", \"2014-08-25\", \"2011-12-11\", \"2017-01-20\"]\n",
    "}\n",
    "df = pd.DataFrame(dogs_data)\n",
    "\n",
    "#Chapter One: Transforming DataFrames:\n",
    "# intro\n",
    "#letâ€™s master the pandas basics. Learn how to inspect DataFrames and perform fundamental manipulations, including sorting rows, subsetting, and adding new columns.\n",
    "# content\n",
    "''' 1 -Introducing DataFrames '''\n",
    "# DataFrames form the core of pandas.\n",
    "# pandas is a Python package for data manipulation and data visualization\n",
    "# pandas is built on top of two essential Python packages, NumPy and Matplotlib\n",
    "# Numpy : Numpy provides multidimensional array objects for easy data manipulation that pandas uses to store data\n",
    "# Matplotlib: Matplotlib has powerful data visualization capabilities that pandas takes advantage of.\n",
    "# There are several ways to store data for analysis, but rectangular data, sometimes called \"tabular data\" is the most common form\n",
    "# Rectangular data OR \"tabular data\" : it is Rows(observation) and Coloumns (Variable or Propery)\n",
    "# Rectangular data OR \"tabular data\" is represnted as a Data Frame object\n",
    "# Every programming language used for data analysis has something similar to Rectangular data, R also has DataFrames, while SQL has database tables.\n",
    "# Each Value within columns has same data type ,but each column can contain differnt data types.\n",
    "# Exploring a DataFrame: when you receive data set for the first time, will use these methods to get a sense of its contents:\n",
    "# df.head() 'method' : returns the first few rows of the DataFrame\n",
    "# df.info() 'method' : displays the names of columns, the data types they contain, and whether they have any missing values.\n",
    "# df.shape 'attribute' : attribute contains a tuple that holds the number of rows followed by the number of columns.\n",
    "# df.describe() 'method' : computes some summary statistics for numerical columns, like mean and median , \"count\" is the number of non-missing values in each column\n",
    "# DataFrames consist of three different components : (Values - Columns - index)\n",
    "# 1- df.values : return the data values in a 2-dimensional NumPy array\n",
    "# 2- df.columns : return coloumns names (Notice that these are Index objects)\n",
    "# 3- df.index : return row (index or name) (Notice that these are Index objects)\n",
    "# Python has a semi-official philosophy on how to write good code called The Zen of Python\n",
    "#  pandas is like a Swiss Army Knife, giving you a variety of tools\n",
    "#__________________________________________________________________________\n",
    "''' 2- Sorting and subsetting '''\n",
    "# we'll cover the two simplest and possibly most important ways to find interesting parts of your DataFrame: (Sorting - subset)\n",
    "# A- Sorting: The first thing you can do is change the order of the rows by sorting them using:\n",
    "# df.sort_values('weight_kg'): sort rows values ascending (by default )depending on weight_kg coloumn\n",
    "# df.sort_values('weight_kg' , ascending=False ) :  sort rows values descending\n",
    "#df.sort_values(['weight_kg' , 'height_cm']): We can sort by multiple variables by passing a list of column names to sort_values. \n",
    "#df.sort_values(['weight_kg' , 'height_cm']): Here, we sort first by weight, then by height.\n",
    "#df.sort_values(['weight_kg' , 'height_cm'],ascending=[True,False])#: first coloumn is ascending order and second coloumn is descendind order\n",
    "'''We may want to zoom in on just one column. We can do this using the name of the DataFrame, followed by square brackets with a column name inside.'''\n",
    "#B-Subseting : Coloumns and Rows\n",
    "# A- Subseting coloumns:\n",
    "# 1- df['column_name']   or  2- df[['col_name_1','col_name_2']] )\n",
    "\n",
    "# B- Subseting rows:\n",
    "# 1- df[df['weight_kg']>50]\n",
    "# 2- df[df['breed' == 'Labrador']]\n",
    "# 3- df[df['date_of_birth'] > '2014-01-20']\n",
    "# 4- df[(df['breed'] == 'Labrador')&(df['color'] == 'Brown')]\n",
    "# 5- df[df['color'].isin(['Brown','Black'])]\n",
    "#_________________________________________________________________________________________________________________________\n",
    "''' 3- New columns'''\n",
    "# when you first receive a DataFrame, the contents aren't exactly what you want. You may have to add new columns derived from existing columns.\n",
    "# Creating and adding new columns can go by many names, including mutating a DataFrame, transforming a DataFrame, and feature engineering. \n",
    "# On the left-hand side of the equals, we use square brackets with the name of the new column we want to create. On the right-hand side, we have the calculation.\n",
    "# add new coloumn calculates BMI for dog as follow: \n",
    "#df['BMI'] = df['weight_kg']/(df['height_cm']**2)\n",
    "'''\n",
    "Multible manipulations:\n",
    "BMI_100 = df[df['BMI'] < 100]\n",
    "BMI_height = BMI_100.sort_values('height_cm',ascending=False)\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd9500-fb51-4ec7-bcf2-c8c9526b3da0",
   "metadata": {},
   "source": [
    "chapter 2 : Aggregating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "865621ab-a9a0-411f-8510-6b910ed4e1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dogs_data = {\n",
    "    \"name\": [\"Bella\", \"Charlie\", \"Lucy\", \"Cooper\", \"Max\"],\n",
    "    \"breed\": [\"Labrador\", \"Poodle\", \"Chow Chow\", \"Schnauzer\", \"Labrador\"],\n",
    "    \"color\": [\"Brown\", \"Black\", \"Brown\", \"Gray\", \"Black\"],\n",
    "    \"height_cm\": [56, 43, 44, 50, 59],\n",
    "    \"weight_kg\": [34, 54, 30, 17, 29],\n",
    "    \"date_of_birth\": [\"2013-07-01\", \"2016-09-16\", \"2014-08-25\", \"2011-12-11\", \"2017-01-20\"]\n",
    "}\n",
    "df = pd.DataFrame(dogs_data)\n",
    "df\n",
    "\n",
    "\n",
    "#Chapter Two : Aggregating DataFrames:\n",
    "# intro: In this chapter, youâ€™ll calculate summary statistics on DataFrame columns, and master grouped summary statistics and pivot tables.\n",
    "# content:\n",
    "'''                      1- Summary statistics            '''\n",
    "# In this chapter, we'll talk about aggregating data(ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª), starting with summary statistics(Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙˆØ¬Ø²Ø©).\n",
    "# One of the most common summary statistics for numeric data is:\n",
    "# 1- df.mean() \n",
    "'''Mean is the average of the data. It's calculated by summing all values in a column and dividing by the number of values and \n",
    "use it to find the central tendency of normally distributed data.'''\n",
    "# 2- df.median()\n",
    "''' is the middle value when the data is sorted. If there's an even number of values, it's the average of the two middle ones.\n",
    "Use it when your data has outliers, as it is not affected by extreme values like the mean.'''\n",
    "# 3- df.mode()\n",
    "''' Mode is the most frequent value in the data. A dataset can have one mode, more than one mode (multimodal), or none.\n",
    " Useful for categorical or discrete data, or when you want to know the most common value '''\n",
    "# 4- df.std()\n",
    "''' Standard Deviation measures how spread out the values are around the mean. A low std means the values are close to the mean; a high std means they are more spread out.\n",
    "Use it to understand the variability in your data.'''\n",
    "#5- df.var() \n",
    "''' Variance is the square of the standard deviation. It also tells you how much the data is spread out, but it's in squared units of the original data.\n",
    "Less interpretable than std in terms of real-world units but still useful for statistical calculations. '''\n",
    "#5- df.sum() \n",
    "# df.agg() \n",
    "\n",
    "''' The .agg() method in pandas is used to apply one or more summary functions to a DataFrame or Series.\n",
    "It is short for aggregate, and is typically used for summarizing data. You can pass built-in functions (like 'mean', 'min', 'max') or custom functions (like a user-defined percentile function). You can apply it to:\n",
    "A single column (Series)\n",
    "Multiple columns (subset of DataFrame)\n",
    "The whole DataFrame\n",
    "Itâ€™s often used with .groupby() to generate grouped summary statistics.\n",
    "\n",
    "agg syntax:\n",
    "1 - agg + one coloumn:\n",
    "df['weight_kg'].agg(['mean' , 'max'])\n",
    "2- agg + multiple coloumns:\n",
    "df[['weight_kg','height_cm']].agg(['median','std'])\n",
    "3- agg + specific coloumns with specific fucction:\n",
    "df.agg({'weight_kg':'median', 'date_of_birth':'min'})\n",
    "4- agg + lambda \n",
    "df['weight_kg'].agg(lambda x : x.min())\n",
    "'''\n",
    "\n",
    "\n",
    "'''                      2- Cumulative Statistics            '''\n",
    "''' \n",
    "Cumulative statistics in pandas are methods that calculate running totals or progressions across rows in a DataFrame or Series.\n",
    "Instead of returning a single summary number, they return a Series of values, where each value is based on the current row and all previous rows.\n",
    "These are useful for time series analysis or tracking data progression over time. '''\n",
    "# pandas also has methods for computing cumulative statistics (Ø¥Ø­ØµØ§Ø¡Ø§Øª ØªØ±Ø§ÙƒÙ…ÙŠØ©):\n",
    "'''\n",
    "1- cumsum()\n",
    "df['weight_kg'].cumsum()\n",
    "2- cumprod()\n",
    "2- df['height_cm'].cumprod() # Ø¨ÙŠØ¶Ø±Ø¨ ÙƒÙ„ Ø¹Ù†ØµØ± ÙÙŠÙ…Ø§ Ù‚Ø¨Ù„Ù‡\n",
    "3- df.[['weight_kg','height_cm']].cummax()\n",
    "'''\n",
    "df[['weight_kg','height_cm']].cummax() #Ø¨ÙŠØ±Ø¬Ø¹ Ø£ÙƒØ¨Ø± Ù‚ÙŠÙ…Ø© Ø¸Ø§Ù‡Ø±Ø© Ø­ØªÙ‰ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©  \n",
    "\n",
    "\n",
    "\n",
    "'''                      3- Counting Categorical Data in Pandas           '''\n",
    "data = {\n",
    "    'name': ['Max', 'Bella', 'Max', 'Charlie', 'Bella', 'Stella', 'Stella'],\n",
    "    'breed': ['Chow Chow', 'Labrador', 'Labrador', 'Poodle', 'Labrador', 'Beagle', 'Beagle'],\n",
    "    'visit_date': ['2024-01-01', '2024-01-02', '2024-01-10', '2024-01-05', '2024-01-15', '2024-01-20', '2024-02-01']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# you'll learn how to summarize categorical data using counting.\n",
    "'''\n",
    "1- Remove dubplicates in one coloumn:\n",
    "df.drop_duplicates(subset='name')\n",
    "\n",
    "2- Remove dubplicates in more than coloumn:\n",
    "df.drop_duplicates(subset=['name', 'breed'])\n",
    "\n",
    "3- count unique values after drop duplicates\n",
    "df['breeds'].value_counts()\n",
    "\n",
    "4- calculate percentage :\n",
    "df['breed'].value_counts(normalize = True)\n",
    "\n",
    "5- Ascending and descending:\n",
    "df['breed'].value_counts(sort= True)\n",
    "'''\n",
    "\n",
    "'''                      3- Grouped summary statistics           '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dogs = pd.DataFrame({\n",
    "    'name':    ['Rex', 'Bella', 'Charlie', 'Max', 'Luna', 'Rocky', 'Lucy', 'Daisy', 'Cooper', 'Milo'],\n",
    "    'breed':   ['Labrador', 'Poodle', 'Beagle', 'Labrador', 'Poodle', 'Bulldog', 'Beagle', 'Poodle', 'Labrador', 'Beagle'],\n",
    "    'color':   ['Black', 'White', 'Brown', 'Black', 'Brown', 'White', 'Black', 'White', 'Brown', 'Black'],\n",
    "    'age':     [5, 3, 4, 6, 2, 4, 5, 3, 1, 6],\n",
    "     'weight': [45, 35, 55, 70, 15, 35, 55, 30, 15, 70]\n",
    "})\n",
    "dogs\n",
    "# you've been calculating summary statistics for all rows of a dataset, but summary statistics can be useful to compare different groups.\n",
    "'''                              group by method                           '''\n",
    "'''\n",
    "The groupby() method in pandas is used to split data into groups based on the values in one or more columns.\n",
    "Once grouped, you can apply aggregate functions (like mean(), sum(), count(), etc.) to each group separately.\n",
    "This is very useful for analyzing patterns or statistics across categories in your dataset.\n",
    "ðŸ§  Think of it like:\n",
    "Split â†’ Apply Function â†’ Combine the result\n",
    "\n",
    "- syntax:\n",
    "#  dataframe.groupby('column_name')[columns_names].methods\n",
    "dogs.groupby('breed')['weight'].max()\n",
    "dogs.groupby(['name','breed'])['age'].mean()\n",
    "dogs.groupby(['color','breed'])[['weight','age']].median()\n",
    "dogs.groupby(['color','breed'])[['weight','age']].agg([min(),median(),mode()]\n",
    "'''\n",
    "'''                      4- Pivot Tables           '''\n",
    "# Pivot tables are another way of calculating grouped summary statistics.\n",
    "# Pivot tables are the standard way of aggregating data in spreadsheets.\n",
    "# essentially another way of performing grouped calculations.\n",
    "# pivot tables are essentially another way of performing grouped calculations.\n",
    "# That is, the .pivot_table() method is an alternative to .groupby().\n",
    "'''\n",
    "syntax:\n",
    "df.pivot_table(values= ... , index= ...., aggfunc= ... , columns= ...)\n",
    "dogs.pivot_table(values = 'age', index ='color', columns ='breed' , aggfunc ='mean')\n",
    "dogs.pivot_table(values = 'weight' , index = 'name')\n",
    "dogs.pivot_table(values = 'weight' , index = 'name' , aggfunc = ['mean','median','max'])\n",
    "dogs.pivot_table(values = 'weight', columns ='breed', index = 'color' , fill_value = 0 ) \n",
    "dogs.pivot_table(values = 'weight', columns ='breed', index = 'color' , fill_value = 0 , margins = True ) \n",
    "# margins: create column and calaulate mean for each row \n",
    "'''\n",
    "dogs.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5365762-5007-4aee-9711-c9ec952ab62b",
   "metadata": {},
   "source": [
    "3 - Slicing and Indexing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3bd2d2-f294-4810-ba16-f4c3a8eaf0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3719449054.py, line 150)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 150\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''3- Pivot tables and Slicing|Subseting '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#Chapter Three : Slicing and Indexing DataFrames\n",
    "# intro: Indexes are supercharged row and column names. Learn how they can be combined with slicing for powerful DataFrame subsetting.\n",
    "# content:\n",
    "import pandas as pd\n",
    "\n",
    "dogs = pd.DataFrame({\n",
    "    'name':    ['Rex', 'Bella', 'Charlie', 'Max', 'Luna', 'Rocky', 'Lucy', 'Daisy', 'Cooper', 'Milo'],\n",
    "    'breed':   ['Labrador', 'Poodle', 'Beagle', 'Labrador', 'Poodle', 'Bulldog', 'Beagle', 'Poodle', 'Labrador', 'Beagle'],\n",
    "    'color':   ['Black', 'White', 'Brown', 'Black', 'Brown', 'White', 'Black', 'White', 'Brown', 'Black'],\n",
    "    'age':     [5, 3, 4, 6, 2, 4, 5, 3, 1, 6],\n",
    "     'weight': [45, 35, 55, 70, 15, 35, 55, 30, 15, 70]\n",
    "})\n",
    "dogs\n",
    "'''                               1- Explicit indexes (Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„ØµØ±ÙŠØ­Ø©)                           '''\n",
    "'''\n",
    "DataFrames are composed of three parts: a NumPy array for the data, and two indexes to store the row and column details.\n",
    "Access columns and indexes :\n",
    "dogs.columns\n",
    "dogs.index\n",
    "dogs.values\n",
    "                                               A- Setting column as index\n",
    "You can move a column from the body of the DataFrame to the index. This is called \"setting an index,\" and it uses the set_index method.                                               \n",
    "1- Set one column:\n",
    "dogs_ind = dogs.set_index('name')\n",
    "\n",
    "2- Set more than column:\n",
    "You can include multiple columns in the index by passing a list of column names to set_index.\n",
    "These are called multi-level indexes, or hierarchical indexes\n",
    "dogs_ind = dogs.set_index(['name','breed'])\n",
    "- name : outer index\n",
    "- breed : inner index\n",
    "\n",
    "                                               B- Remove column index\n",
    "To undo what you just did, you can reset the index - that is, you remove it. This is done via: reset_index\n",
    "1- Remove index without removing it's location\n",
    "dogs.reset_index()\n",
    "2- Remove index and it's location\n",
    "dogs.reset_index(drop = True)\n",
    "                                          (Question: Why we should bother with indexes?)\n",
    "Answer: Indexes make subsetting simpler, notice the following codes :\n",
    "1- subset without column index:  dogs[dogs['color'].isin(['Black','Brown'])]\n",
    "2- subset wwith column index: dogs_ind.loc[['Black','Brown']]\n",
    "\n",
    "*The values in the index don't need to be unique.\n",
    "\n",
    "\n",
    "\n",
    "                                                 C- Subset outer index \n",
    "To take a subset of rows at the outer level index, you pass a list of index values to loc:\n",
    "sytax: df.loc[['index_1','index_2','index_3' , ...]]\n",
    "ex:\n",
    "dogs_ind.loc[['Labrador','Poodle']] \n",
    "\n",
    "                                                 D- Subset inner index\n",
    "To subset on inner levels, you need to pass a list of tuples :\n",
    "syntax : df.loc[[('outter_index_1','inner_index_1'),('outter_index_2','inner_index_2'),...]]\n",
    "ex:\n",
    "dogs_ind = dogs.set_index(['breed','color'])\n",
    "dogs_ind.loc[[('Labrador','Black'),('Poodle','Brown'),('Bulldog','White')]]\n",
    "\n",
    "\n",
    "                                                 E- Sort by index\n",
    "\n",
    "1- in last chapter we learned to sort using sort_values:\n",
    "dogs_ind = dogs.set_index(['breed','color'])\n",
    "dogs_ind.sort_values('age')\n",
    "\n",
    "2- You can also sort by index values using sort_index. By default, it sorts all index levels from outer to inner, in ascending order:\n",
    "dogs_ind = dogs.set_index(['breed','color'])\n",
    "dogs_ind.sort_index()\n",
    "\n",
    "2.1 - You can control the sorting by passing lists to the level and ascending arguments.\n",
    "dogs_ind = dogs.set_index(['breed','color'])\n",
    "dogs_ind.sort_index(level = ['breed','color'] , ascending = [True , True])\n",
    "\n",
    "''' \n",
    "'''\n",
    "                                           2- Slicing and subsetting with .loc and .iloc\n",
    "                                                                  \n",
    "Slicing is a technique for selecting consecutive elements from objects.\n",
    "                                           A-LIST slicing\n",
    "breeds = ['Labrador', 'Poodle', 'Beagle', 'Labrador', 'Poodle', 'Bulldog', 'Beagle', 'Poodle', 'Labrador', 'Beagle']\n",
    "breeds[:] all elements\n",
    "breeds[:5] elements from 0 : 4 last position  not included\n",
    "\n",
    "                                            B- Data frame slicing\n",
    "                        '   you need to sort the index before data frame slicing '\n",
    "sort_dogs_df= dogs.set_index(['breed','color']).sort_index(level = ['breed','color'] , ascending = [True,False])\n",
    "                                            \n",
    "                                            B.1 - Slicing the outer index level        \n",
    "To slice rows at the outer level of an index, you call loc, passing the first and last values separated by a colon. \n",
    "note: when you slice by loc, pass values directly ,but while subset by loc, pass list of values\n",
    "syntax:\n",
    "1- slice outter indexes only : \n",
    "df.loc['outter_index' : 'outter_index']\n",
    "dogs_ind.loc['Beagle':'Labrador']\n",
    "2- slice outter indexes + columns :\n",
    "df.loc['outter_index' : 'outter_index' , 'col_name':'col_name']\n",
    "dog_ind.loc['Beagle':'Labrador' , 'name':'age']\n",
    "                                            \n",
    "                                            D - Slicing the inner index level\n",
    "                                        \n",
    "- The same technique doesn't work on inner index levels (which you access directly on inner index), because it return empty data frame\n",
    "dogs_ind = dogs.set_index(['breed','color']).sort_index()\n",
    "dogs_ind.loc['Black':'Brown'] note: 'Black':'Brown' are inner indexes\n",
    "\n",
    "\n",
    "                             D.1- slicing inner indexes only (without columns)\n",
    "- Slicing the inner index levels correctly:\n",
    "The correct approach to slicing at inner index levels is to pass the first and last positions as tuples.\n",
    "syntax:\n",
    "df.loc[('outter_ind','inner_ind'):('outter_ind_2','inner_ind_2')]\n",
    "dogs_ind = dogs.set_index(['breed','color']).sort_index()\n",
    "dogs_ind.loc[('Labrador','Black'):('Poodle','Brown')] \n",
    "\n",
    "                                            D.2- slicing inner indexes  with columns\n",
    "syntax:\n",
    "df.loc[('outter_ind','inner_ind'):('outter_ind_2','inner_ind_2') , 'col_name':'col_name']\n",
    "dogs_ind = dogs.set_index(['breed','color']).sort_index()\n",
    "dogs_ind.loc[('Labrador','Black'):('Poodle','Brown') , 'name':'age'] \n",
    "\n",
    "\n",
    "\n",
    "                                            E - Slicing columns\n",
    "syntax:\n",
    "df.loc[: , 'col_name':'col_name']\n",
    "ex:\n",
    "dogs_ind = dogs.set_index(['breed','color']).sort_index()\n",
    "dogs_ind.loc[: , 'name':'age']\n",
    "\n",
    "                                            F - Slicing by date\n",
    "syntax: \n",
    "df.loc['start_date':'end_date']\n",
    "ex:\n",
    "dogs_ind.loc['2024-01-01' : '2026-06-01']\n",
    "                                             F.1 - Slicing by partial date\n",
    "syntax: \n",
    "df.loc['Start_Year':'end_Year']\n",
    "ex:\n",
    "dogs_ind.loc['2024' : '2026']\n",
    "\n",
    "\n",
    "                                             G- slice by row and column using iloc[]\n",
    "\n",
    "dogs_ind.iloc[2:4 , 1:3]\n",
    "'''\n",
    "                                                          \n",
    "\n",
    "\n",
    "                                                       '''3- Pivot tables and Slicing|Subseting ''' \n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'employee': ['Ali', 'Ali', 'Lina', 'Lina'],\n",
    "    'branch': ['Riyadh', 'Jeddah', 'Riyadh', 'Jeddah'],\n",
    "    'sales': [1000, 1500, 1200, 1300]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "_______________________________\n",
    "- syntax pivot table:\n",
    "df.pivot_table(values='sales', index='employee', columns='branch', aggfunc='sum', fill_value=0)\n",
    "Pivot tables are just DataFrames with sorted indexes.\n",
    "You can apply all standard DataFrame operations like:\n",
    "1- .mean(), .sum(), .std() etc.\n",
    "2- Slicing and subsetting using .loc, .iloc, etc.\n",
    "\n",
    "Axis Parameter:\n",
    "axis=0 â†’ operate column-wise (down the rows).\n",
    "axis=1 â†’ operate row-wise (across the columns).\n",
    "df_pv = df.pivot_table(\n",
    "    values='sales',\n",
    "    index='employee',\n",
    "    columns='branch',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "df_pv.mean(axis=0)  # average sales per branch\n",
    "df_pv.mean(axis=1)  # average sales per employee\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f978b1-7e5f-4c80-8c6b-4f7cad66728a",
   "metadata": {},
   "source": [
    "4- Creating and Visualizing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5665387-a7c1-4413-88e5-45f1fdb1f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chapter Four : Creating and Visualizing DataFrames\n",
    "# intro: Learn to visualize the contents of your DataFrames, handle missing data values, and import data from and export data to CSV files.\n",
    "# content:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "                                             1- Visualizing your data\n",
    "Plots are a powerful way to share the insights you've gained from your data.\n",
    "Remember when we talked about matplotlib at the beginning of the course?\n",
    "We'll need to import matplotlib-dot-pyplot as plt in order to display our visualizations.\n",
    "                                             A- Histogram\n",
    "                                             \n",
    "Let's create a histogram, We can create a histogram of the height variable by selecting the column and calling dot-hist:\n",
    "ex:\n",
    "dogs['height_cm'].hist(bins=5)\n",
    "plt.title('Height Distribution of Dogs')\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Number of Dogs')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "                                             B- Bar plot\n",
    "Bar plots can reveal relationships between a categorical variable and a numeric variable, like breed and weight\n",
    "we can create a bar plot from the mean weights using the plot method, setting \"kind\" equal to \"bar.\"\n",
    "ex:\n",
    "dogs.groupby('breed')['weight_kg'].mean().plot(kind='bar', title='Average Weight by Breed')\n",
    "plt.ylabel('Average Weight (kg)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "                                             \n",
    "                                             C- Line Plot\n",
    "Line plots are great for visualizing changes in numeric variables over time.                                             \n",
    "sully = pd.DataFrame({\n",
    "    'month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],\n",
    "    'weight_kg': [20, 21, 19, 22, 21, 23]\n",
    "})\n",
    "\n",
    "sully.plot(x='month', y='weight_kg', kind='line', marker='o', title='Sully\\'s Weight Over Time')\n",
    "plt.ylabel('Weight (kg)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "                                            D- Scatter plot\n",
    "Scatter plots are great for visualizing relationships between two numeric variables (height - weight)\n",
    "dogs.plot(x='height_cm', y='weight_kg', kind='scatter', title='Height vs. Weight')\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Weight (kg)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "                                             E- Layering plots\n",
    "Plots can also be layered on top of one another\n",
    "we can create a histogram of female dogs' heights, and put a histogram of male dogs' heights on top\n",
    "# Female dogs\n",
    "dogs[dogs['sex'] == 'Female']['height_cm'].hist(alpha=0.5, label='Female')\n",
    "# Male dogs\n",
    "dogs[dogs['sex'] == 'Male']['height_cm'].hist(alpha=0.5, label='Male')\n",
    "\n",
    "plt.title('Height Distribution by Sex')\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Number of Dogs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "                                            F- (Data camp exercises on Creating and Visualizing DataFrames )\n",
    "1- bar plot:\n",
    "\n",
    "# Look at the first few rows of data\n",
    "print(avocados.head())\n",
    "# Get the total number of avocados sold of each size\n",
    "nb_sold_by_size = avocados.groupby('size')['nb_sold'].sum()\n",
    "# Create a bar plot of the number of avocados sold by size\n",
    "nb_sold_by_size.plot(kind = 'bar')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "2- line plot\n",
    "\n",
    "# Get the total number of avocados sold on each date\n",
    "nb_sold_by_date = avocados.groupby('date')['nb_sold'].sum()\n",
    "# Create a line plot of the number of avocados sold by date\n",
    "nb_sold_by_date.plot(kind = 'line')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "3- scatter plot:\n",
    "avocados.plot(x='nb_sold' , y ='avg_price' , kind = 'scatter' ,title='Number of avocados sold vs. average price')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "4- histogram:\n",
    "\n",
    "# Modify bins to 20\n",
    "avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5, bins = 20)\n",
    "# Modify bins to 20\n",
    "avocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5 , bins = 20)\n",
    "# Add a legend\n",
    "plt.legend([\"conventional\", \"organic\"])\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "                                                        2- Missing values\n",
    "- methods to search for missing values in data frames:\n",
    "\n",
    "1- df.isna - return True and False (True = NaN / False = no missing value ) \n",
    "2- df.isna().any() return all column with True and False (True = this column has missing values / False = no missing value)\n",
    "3- df.isna().sum() calculate missing values number in each column\n",
    "\n",
    "- we can visualize missing values as follow:\n",
    "missing_values = employees_df.isna().sum().plot(kind = 'bar')\n",
    "\n",
    "- How to deal with data frame has missing values, there are two senarios:\n",
    "1- drop all row with missing values (this may not be ideal)\n",
    "employees_df.dropna()\n",
    "\n",
    "2-replace missing values with another value:\n",
    "employees_df.fillna()\n",
    "\n",
    "\n",
    "                                             (Data camp exercises on missing values)\n",
    "1- missing values:\n",
    "\n",
    "# Check individual values for missing values\n",
    "print(avocados_2016.isna())\n",
    "Check each column for missing values\n",
    "print(avocados_2016.isna().any())\n",
    "Bar plot of missing values by variable\n",
    "avocados_2016.isna().sum().plot(kind = 'bar')\n",
    "plt.show()\n",
    "\n",
    "2- drop rows with missing values:\n",
    "\n",
    "# Remove rows with missing values\n",
    "avocados_complete = avocados_2016.dropna()\n",
    "# Check if any columns contain missing values\n",
    "print(avocados_complete.isna().any())\n",
    "\n",
    "\n",
    "3- Replacing missing values\n",
    "\n",
    "# From previous step\n",
    "cols_with_missing = [\"small_sold\", \"large_sold\", \"xl_sold\"]\n",
    "avocados_2016[cols_with_missing].hist()\n",
    "plt.show()\n",
    "# Fill in missing values with 0\n",
    "avocados_filled = avocados_2016.fillna(0)\n",
    "# Create histograms of the filled columns\n",
    "avocados_filled[cols_with_missing].hist()\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                                 3- Creating DataFrames\n",
    "After learning how to use DataFrames, the next step is learning how to create them.\n",
    "There are many ways to create DataFrames from scratch, but we'll discuss two ways:\n",
    "A- From a list of dictionaries\n",
    "B- From a dictionary of lists From a dictionary of lists â†’ builds the DataFrame column by column\n",
    "\n",
    "                                                   A- From a list of dictionaries\n",
    "                                                   \n",
    "From a list of dictionaries â†’ builds the DataFrame row by row \n",
    "\n",
    "data = [\n",
    "    {\"name\": \"Ginger\", \"breed\": \"Dachshund\", \"height_cm\": 22, \"weight_kg\": 10},\n",
    "    {\"name\": \"Scout\", \"breed\": \"Dalmatian\", \"height_cm\": 59, \"weight_kg\": 25}\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "                                                  B- From a dictionary of lists \n",
    "From a dictionary of lists â†’ builds the DataFrame column by column\n",
    "data = {\n",
    "    \"name\": [\"Ginger\", \"Scout\"],\n",
    "    \"breed\": [\"Dachshund\", \"Dalmatian\"],\n",
    "    \"height_cm\": [22, 59],\n",
    "    \"weight_kg\": [10, 25]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                   \n",
    "\n",
    "                                                         4- Reading and writing CSVs\n",
    "Typing out your data entry-by-entry isn't usually the most efficient way\n",
    "to get your data into a DataFrame. (Manual data entry is inefficient)\n",
    "- CSV = Comma-Separated Values.\n",
    "It's a plain text file that stores tabular data, similar to a pandas DataFrame\n",
    "Each row is a line, and values are separated by commas.\n",
    "# csv to data frame\n",
    "Use pd.read_csv(\"file_path.csv\") to read CSV data into pandas.\n",
    "# data frame to csv\n",
    "Use df.to_csv(\"new_file.csv\") to save a DataFrame to a new CSV file.\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "df.to_csv(\"updated_dogs.csv\", index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d93ac-0d0c-4505-a658-a080acdd8448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
